{
  "precision_at_k": 0.8,
  "mrr": 0.5066666666666667,
  "avg_relevancia": 0.7,
  "avg_fidelidad": 0.5,
  "avg_precision": 0.3,
  "avg_overall": 0.5,
  "avg_retrieval_time": 3.306975269317627,
  "avg_generation_time": 7.0493920803070065,
  "avg_total_time": 10.357158708572388,
  "total_questions": 5,
  "questions_with_correct_doc": 4,
  "metrics_by_category": {
    "estatutos": {
      "count": 2,
      "precision_at_k": 1.0,
      "avg_relevancia": 0.5,
      "avg_fidelidad": 0.5,
      "avg_precision": 0.5,
      "avg_overall": 0.5,
      "avg_time": 11.503381967544556
    },
    "general": {
      "count": 2,
      "precision_at_k": 1.0,
      "avg_relevancia": 0.75,
      "avg_fidelidad": 0.5,
      "avg_precision": 0.25,
      "avg_overall": 0.5,
      "avg_time": 9.621162056922913
    },
    "reglamentos": {
      "count": 1,
      "precision_at_k": 0.0,
      "avg_relevancia": 1.0,
      "avg_fidelidad": 0.5,
      "avg_precision": 0.0,
      "avg_overall": 0.5,
      "avg_time": 9.536705493927002
    }
  },
  "metrics_by_question_type": {
    "procedimental": {
      "count": 2,
      "precision_at_k": 1.0,
      "avg_relevancia": 0.5,
      "avg_fidelidad": 0.5,
      "avg_precision": 0.5,
      "avg_overall": 0.5,
      "avg_time": 11.503381967544556
    },
    "factual": {
      "count": 3,
      "precision_at_k": 0.6666666666666666,
      "avg_relevancia": 0.8333333333333334,
      "avg_fidelidad": 0.5,
      "avg_precision": 0.16666666666666666,
      "avg_overall": 0.5,
      "avg_time": 9.593009869257608
    }
  }
}