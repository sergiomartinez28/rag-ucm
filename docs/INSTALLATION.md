# Gu√≠a de Instalaci√≥n y Uso - RAG-UCM

## üìã Tabla de Contenidos

1. [Requisitos](#requisitos)
2. [Instalaci√≥n](#instalaci√≥n)
3. [Configuraci√≥n](#configuraci√≥n)
4. [Preparaci√≥n de Datos](#preparaci√≥n-de-datos)
5. [Uso del Sistema](#uso-del-sistema)
6. [Evaluaci√≥n](#evaluaci√≥n)
7. [Troubleshooting](#troubleshooting)

---

## üîß Requisitos

### Hardware m√≠nimo
- **RAM**: 8GB (16GB recomendado)
- **Disco**: 10GB libres
- **CPU**: 4 cores recomendados
- **GPU**: Opcional, acelera generaci√≥n (recomendada 8GB+ VRAM)

> üí° **Nota sobre rendimiento**: El LLM usa cuantizaci√≥n 4-bit autom√°ticamente para reducir ~50% el uso de VRAM y acelerar la generaci√≥n.

### Software
- Python 3.10 o superior
- pip (gestor de paquetes Python)
- Git (opcional, para clonar el repositorio)

---

## üì¶ Instalaci√≥n

### Opci√≥n 1: Instalaci√≥n local

```bash
# 1. Navegar al directorio del proyecto
cd "rag-ucm"

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
# En macOS/Linux:
source venv/bin/activate
# En Windows:
venv\Scripts\activate

# 4. Actualizar pip
pip install --upgrade pip

# 5. Instalar dependencias
pip install -r requirements.txt

```

---

## ‚öôÔ∏è Configuraci√≥n

Toda la configuraci√≥n est√° centralizada en `src/config.py` con valores optimizados:

| Par√°metro | Valor | Descripci√≥n |
|-----------|-------|-------------|
| **Embeddings** | BAAI/bge-m3 | Modelo multiling√ºe (1024 dims) |
| **Re-ranker** | BAAI/bge-reranker-base | Cross-encoder para precisi√≥n |
| **LLM** | Qwen/Qwen2.5-3B-Instruct | Cuantizado 4-bit autom√°ticamente |
| chunk_size | 1000 | Tama√±o de chunks en caracteres |
| chunk_overlap | 200 | Solapamiento entre chunks |
| top_k_retrieval | 10 | Documentos iniciales a recuperar |
| top_k_rerank | 3 | Documentos finales tras re-ranking |
| hybrid_alpha | 0.45 | Balance BM25/sem√°ntico |
| max_new_tokens | 100 | Tokens m√°ximos de respuesta |
| temperature | 0.1 | Determinismo de generaci√≥n |

Para modificar, edita directamente `src/config.py`.

---

## üìö Preparaci√≥n de Datos

### 1. Obtener documentos

Descarga documentos oficiales de la UCM:

- Normativas TFG/TFM de tu facultad
- Calendarios acad√©micos
- Normativa de permanencia
- Gu√≠as de procedimientos

Col√≥calos en `data/raw/`

### 2. Construir √≠ndices

```bash
# Usando CLI
python cli.py build --path ./data/raw

# El proceso puede tardar varios minutos
# Ver√°s el progreso en la terminal
```

### 3. Verificar √≠ndices

```bash
# Ver estad√≠sticas
python cli.py stats
```

Deber√≠as ver algo como:

```
üìä Estad√≠sticas RAG-UCM

√çndices:
  ‚Ä¢ Total chunks: 245
  ‚Ä¢ Vectores FAISS: 245
  ‚Ä¢ Modelo embeddings: bge-m3
  ‚Ä¢ Dimensi√≥n: 1024
  ‚Ä¢ Longitud promedio: 487 palabras
```

---

## üöÄ Uso del Sistema

### Interfaz Web (Streamlit)

```bash
streamlit run app.py
```

Abre tu navegador en http://localhost:8501

**Caracter√≠sticas:**
- Interfaz visual amigable
- Configuraci√≥n en tiempo real
- Visualizaci√≥n de fuentes
- M√©tricas de verificaci√≥n

### L√≠nea de Comandos (CLI)

#### Hacer una pregunta

```bash
python cli.py ask "¬øCu√°l es el plazo para presentar el TFM?"
```

#### Con opciones avanzadas

```bash
python cli.py ask "¬øCu√°ntos cr√©ditos puedo convalidar?" \
  --top-k 7 \
  --verbose
```

#### Modo interactivo

```bash
python cli.py interactive
```

Permite hacer m√∫ltiples preguntas en una sesi√≥n.

### Como librer√≠a Python

```python
from src.pipeline import RAGPipeline

# Inicializar
rag = RAGPipeline()

# Hacer pregunta
result = rag.query("¬øCu√°ndo es el plazo del TFG?")

# Mostrar respuesta
print(result['answer'])

# Mostrar fuentes
for source in result['sources']:
    print(f"[{source['id']}] {source['title']}")

# Verificaci√≥n
if 'verification' in result:
    print(f"Fidelidad: {result['verification']['fidelity_score']:.2%}")
```

---

## üìä Evaluaci√≥n

### Crear conjunto de evaluaci√≥n

Crea un archivo `evaluation/questions.json`:

```json
[
  {
    "question": "¬øCu√°l es el plazo para presentar el TFM?",
    "expected_answer": "El plazo es...",
    "source_doc": "normativa_tfm_2024.pdf"
  },
  ...
]
```

### Ejecutar evaluaci√≥n (TODO: implementar)

```bash
python scripts/evaluate.py --questions evaluation/questions.json
```

### M√©tricas RAGAS

El sistema incluye verificaci√≥n autom√°tica con m√©tricas de:
- **Fidelidad**: ¬øLa respuesta est√° respaldada por los documentos?
- **Relevancia**: ¬øLos documentos recuperados son relevantes?
- **Completitud**: ¬øLa respuesta es completa?

---

## üîß Troubleshooting

### Problema: "No se encuentran √≠ndices"

**Soluci√≥n**: Ejecuta `python cli.py build` primero.

### Problema: "Out of memory"

**Soluciones**:
1. El sistema ya usa cuantizaci√≥n 4-bit autom√°ticamente (~4GB VRAM)
2. Reduce `top_k_retrieval` en `src/config.py`
3. Usa un LLM m√°s peque√±o (Qwen2.5-1.5B-Instruct)
4. Cierra otras aplicaciones que usen GPU

### Problema: "Modelo no encontrado"

**Soluci√≥n**: Los modelos se descargan autom√°ticamente de HuggingFace la primera vez. Aseg√∫rate de tener conexi√≥n a internet.

### Problema: Respuestas lentas

**Soluciones**:
1. Si tienes GPU NVIDIA, instala `torch` con CUDA:
   ```bash
   pip install torch --index-url https://download.pytorch.org/whl/cu118
   ```
2. Reduce `TOP_K_RERANK` a 3
3. Usa un modelo m√°s peque√±o

### Problema: El sistema "alucina" (inventa informaci√≥n)

**Soluciones**:
1. Activa `ENABLE_VERIFICATION=true`
2. Reduce `TEMPERATURE` a 0.1-0.2
3. Aumenta `VERIFICATION_THRESHOLD`
4. Revisa que los documentos sean completos y claros

---

## üìù Siguiente Pasos

1. **Expandir documentos**: A√±ade m√°s normativas a `data/raw/`
2. **Fine-tuning**: Considera hacer fine-tuning del LLM con ejemplos UCM
3. **Evaluaci√≥n formal**: Crea un conjunto de test con 100+ preguntas
4. **Despliegue**: Dockeriza y despliega en servidor interno

---

## üÜò Soporte

Para dudas o problemas:
1. Revisa la documentaci√≥n en `docs/`
2. Consulta el README principal
3. Contacta: sergma22@ucm.es

---

**¬°Buena suerte con tu TFM! üéì**
