# RAG-UCM â€” Asistente AcadÃ©mico con Modelos Open Source

## ğŸ“Œ DescripciÃ³n

**TÃ­tulo**: "RAG ligero para asistencia acadÃ©mica en la Universidad Complutense de Madrid: recuperaciÃ³n semÃ¡ntica, generaciÃ³n explicable y control de alucinaciones con modelos open source"

RAG-UCM es un asistente inteligente basado en **Retrieval-Augmented Generation (RAG)** para responder preguntas sobre normativa acadÃ©mica de la Universidad Complutense de Madrid (UCM). 

### CaracterÃ­sticas principales:
- ğŸ” **BÃºsqueda hÃ­brida**: Combina BM25 (bÃºsqueda lÃ©xica) + embeddings semÃ¡nticos
- ğŸ¯ **Re-ranking inteligente**: Cross-encoder para mÃ¡xima precisiÃ³n
- âœ… **VerificaciÃ³n de fidelidad**: Control automÃ¡tico de alucinaciones
- ğŸ“š **Citas obligatorias**: Siempre referencia las fuentes oficiales
- ğŸ”“ **100% Open Source**: Sin dependencias comerciales

---

## ğŸ¯ Objetivo e HipÃ³tesis

### Objetivo
Desarrollar un asistente de preguntas y respuestas para estudiantes de la UCM que responda dudas prÃ¡cticas (normativa TFG/TFM, matrÃ­culas, reconocimiento de crÃ©ditos, becas, plazos administrativosâ€¦) citando siempre las fuentes oficiales, usando Ãºnicamente software y modelos open source y ejecutÃ¡ndose en hardware local/modesto.

### HipÃ³tesis
Un sistema RAG "ligero", basado en bÃºsqueda hÃ­brida, re-ranking cruzado y verificaciÃ³n de fidelidad, puede ofrecer respuestas Ãºtiles y fieles a normativa universitaria sin necesidad de usar grandes modelos privados/comerciales.

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
rag-ucm/
â”œâ”€â”€ app.py                  # Interfaz web Streamlit
â”œâ”€â”€ cli.py                  # Interfaz lÃ­nea de comandos
â”œâ”€â”€ process_documents.py    # Script para indexar documentos
â”œâ”€â”€ evaluate_rag.py         # Script de evaluaciÃ³n del sistema
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ pytest.ini              # ConfiguraciÃ³n de tests
â”œâ”€â”€ LICENSE                 # Licencia MIT
â”œâ”€â”€ README.md               # Este archivo
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Documentos originales (PDFs/HTML)
â”‚   â”œâ”€â”€ processed/          # Ãndices FAISS y BM25
â”‚   â””â”€â”€ evaluation/         # Dataset y resultados de evaluaciÃ³n
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n centralizada (Pydantic)
â”‚   â”œâ”€â”€ preprocessor.py     # ExtracciÃ³n y chunking de documentos
â”‚   â”œâ”€â”€ indexer.py          # IndexaciÃ³n FAISS + BM25
â”‚   â”œâ”€â”€ retrieval.py        # BÃºsqueda hÃ­brida + re-ranking
â”‚   â”œâ”€â”€ generator.py        # GeneraciÃ³n de respuestas con LLM
â”‚   â”œâ”€â”€ verifier.py         # VerificaciÃ³n de fidelidad
â”‚   â”œâ”€â”€ pipeline.py         # Pipeline completo RAG
â”‚   â”œâ”€â”€ prompt_loader.py    # Carga de prompts externos
â”‚   â”œâ”€â”€ utils.py            # Utilidades (timing, memoria)
â”‚   â””â”€â”€ evaluator/          # MÃ³dulo de evaluaciÃ³n
â”‚       â”œâ”€â”€ dataset_generator.py
â”‚       â”œâ”€â”€ rag_evaluator.py
â”‚       â”œâ”€â”€ llm_judge.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ tests/                  # Tests unitarios
â”‚   â”œâ”€â”€ conftest.py         # Fixtures compartidos
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â”œâ”€â”€ test_utils.py
â”‚   â””â”€â”€ test_metrics.py
â”‚
â”œâ”€â”€ prompts/                # Plantillas de prompts
â”‚   â”œâ”€â”€ system_prompt.txt
â”‚   â”œâ”€â”€ user_prompt.txt
â”‚   â””â”€â”€ judge_*.txt
â”‚
â””â”€â”€ docs/
    â””â”€â”€ INSTALLATION.md     # GuÃ­a detallada de instalaciÃ³n
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos previos
- Python 3.10+
- 8GB RAM mÃ­nimo (16GB recomendado)
- GPU opcional (acelera generaciÃ³n, funciona en CPU)
- 10GB espacio en disco

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/rag-ucm.git
cd rag-ucm

# Crear entorno virtual
python -m venv .venv

# Activar entorno
# En Windows:
.venv\Scripts\activate
# En Linux/Mac:
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

> ğŸ’¡ **ConfiguraciÃ³n**: Todos los parÃ¡metros estÃ¡n en `src/config.py` con valores optimizados.

### PreparaciÃ³n de datos

```bash
# 1. Colocar documentos PDF/HTML en data/raw/

# 2. Procesar e indexar documentos
python process_documents.py
```

---

## ğŸ“– Uso

### Interfaz web (Streamlit)

```bash
streamlit run app.py
```

Abre tu navegador en `http://localhost:8501`

### CLI

```bash
# Hacer una pregunta
python cli.py ask "Â¿CuÃ¡ndo es el plazo para presentar el TFM?"

# Construir Ã­ndices
python cli.py build --path ./data/raw

# Ver estadÃ­sticas
python cli.py stats
```

### Como librerÃ­a

```python
from src.pipeline import RAGPipeline

# Inicializar el pipeline
rag = RAGPipeline()

# Hacer una pregunta
response = rag.query("Â¿CuÃ¡ntos crÃ©ditos puedo convalidar?")

print(response['answer'])
print(response['sources'])
```

### Tests

```bash
# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=src

# Tests especÃ­ficos
pytest tests/test_config.py -v
```

---

## ğŸ”¬ MetodologÃ­a TÃ©cnica

### 1. ColecciÃ³n de Documentos
- Normativas TFG/TFM por facultad
- Calendarios acadÃ©micos y plazos
- Procedimientos de reconocimiento/convalidaciÃ³n
- Normativa de permanencia
- Tasas y precios pÃºblicos

### 2. Preprocesado
- ExtracciÃ³n de texto desde PDF (PyMuPDF/pdfplumber) y HTML
- Limpieza y normalizaciÃ³n
- Chunking semÃ¡ntico (~1000 tokens, solape 200)
- PreservaciÃ³n de metadatos (tÃ­tulo, facultad, fecha, URL)

### 3. IndexaciÃ³n
- **Embeddings**: BAAI/bge-m3 (1024 dimensiones)
- **Ãndice vectorial**: FAISS (IndexFlatIP)
- **Ãndice lÃ©xico**: BM25 con tokenizador espaÃ±ol

### 4. RecuperaciÃ³n
1. BÃºsqueda hÃ­brida:
   - Similitud semÃ¡ntica (FAISS, top-10)
   - BM25 (tÃ©rminos exactos, top-10)
2. FusiÃ³n con Reciprocal Rank Fusion (alpha=0.45)
3. Re-ranking con cross-encoder (BAAI/bge-reranker-base)
4. Filtrado por umbral de score (min=0.5)
5. Top-3 documentos finales

### 5. GeneraciÃ³n
- **LLM**: Qwen/Qwen2.5-3B-Instruct (cuantizado 4-bit)
- CuantizaciÃ³n automÃ¡tica para reducir ~50% uso de VRAM
- Prompt con instrucciones de citar fuentes
- Retry inteligente con contexto reducido si abstiene
- MÃ¡ximo 100 tokens, temperatura 0.1

### 6. VerificaciÃ³n de Fidelidad
- EvaluaciÃ³n automÃ¡tica de cada afirmaciÃ³n
- DetecciÃ³n de posibles alucinaciones
- Advertencias cuando la informaciÃ³n no estÃ¡ respaldada

---

## ğŸ“Š EvaluaciÃ³n

El sistema incluye un framework de evaluaciÃ³n completo con:

### GeneraciÃ³n de Dataset
```bash
# Generar preguntas desde chunks (una vez)
python evaluate_rag.py generate --num-samples 100
```

### Ejecutar EvaluaciÃ³n
```bash
# Evaluar con dataset existente
python evaluate_rag.py evaluate

# EvaluaciÃ³n rÃ¡pida (100 preguntas)
python evaluate_rag.py evaluate --limit 100
```

### MÃ©tricas
- **Precision@k**: Documento correcto en top-k resultados
- **Relevancia**: Â¿La respuesta responde a la pregunta?
- **Fidelidad**: Â¿La respuesta se basa en los documentos?
- **PrecisiÃ³n**: Â¿La respuesta es correcta vs referencia?
- **Tasa de abstenciÃ³n**: Cuando el sistema dice "no sÃ©"

---

## ğŸ¯ Alcance Funcional

### âœ… El sistema PUEDE:
- Responder preguntas sobre normativa UCM en lenguaje natural
- Recuperar fragmentos relevantes de documentos oficiales
- Generar respuestas claras en espaÃ±ol con tono administrativo
- Incluir citas precisas de documentos originales
- Indicar cuando no tiene informaciÃ³n suficiente

### âŒ El sistema NO:
- Da consejo legal personalizado
- Hace interpretaciones acadÃ©micas subjetivas
- Sustituye a secretarÃ­a (siempre remite a la fuente)

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Modelos
- **Embeddings**: BAAI/bge-m3 (1024 dims, multilingÃ¼e)
- **Re-ranking**: BAAI/bge-reranker-base (cross-encoder)
- **GeneraciÃ³n**: Qwen/Qwen2.5-3B-Instruct

### LibrerÃ­as principales
- `transformers` - Modelos de HuggingFace
- `sentence-transformers` - Embeddings
- `faiss-cpu` - BÃºsqueda vectorial
- `rank-bm25` - BÃºsqueda lÃ©xica
- `pydantic` - ValidaciÃ³n de configuraciÃ³n
- `streamlit` - Interfaz web
- `typer` + `rich` - CLI

---

## ğŸ“… Estado del Proyecto

- âœ… **Fase 1**: DefiniciÃ³n del alcance y selecciÃ³n de normativas
- âœ… **Fase 2**: AdquisiciÃ³n y limpieza de datos (PDFs/HTML)
- âœ… **Fase 3**: Prototipo RAG bÃ¡sico con recuperaciÃ³n + generaciÃ³n
- âœ… **Fase 4**: BÃºsqueda hÃ­brida (BM25 + semÃ¡ntica) + re-ranking
- âœ… **Fase 5**: VerificaciÃ³n de fidelidad y control de abstenciones
- âœ… **Fase 6**: EvaluaciÃ³n con dataset de 449 preguntas
- âœ… **Fase 7**: Demo Streamlit + CLI

### Resultados de EvaluaciÃ³n

| MÃ©trica | Valor |
|---------|-------|
| Overall Score | 0.72 |
| Precision | 0.62 |
| Fidelidad | 0.74 |
| AbstenciÃ³n | 0.0% |
| Tiempo retrieval | ~5s |
| Tiempo generaciÃ³n | ~50s |

---

## ğŸ“ Limitaciones

- Cobertura limitada a documentos pÃºblicos UCM incluidos
- Los modelos pequeÃ±os pueden tener lÃ­mites de comprensiÃ³n
- Requiere actualizaciÃ³n periÃ³dica de normativas
- No sustituye consulta directa con secretarÃ­a

---

## ğŸ”® Trabajo Futuro

- Expandir a todas las facultades UCM
- IntegraciÃ³n con sistemas de gestiÃ³n acadÃ©mica
- Soporte multiidioma (inglÃ©s para estudiantes internacionales)
- Fine-tuning del LLM con lenguaje administrativo UCM
- Despliegue interno para secretarÃ­as

---

## ğŸ“„ Licencia

MIT License - Ver archivo `LICENSE` para mÃ¡s detalles

---

## ğŸ‘¤ Autor

**Sergio MartÃ­n**
- TFM - MÃ¡ster [nombre del mÃ¡ster]
- Universidad Complutense de Madrid
- sergma22@ucm.es

---

## ğŸ™ Agradecimientos

- Universidad Complutense de Madrid por la disponibilidad de normativas pÃºblicas
- Comunidad open source de HuggingFace y LangChain
- [Nombre del tutor/a] por la supervisiÃ³n del TFM
